// 25MotionDetetion_ThreeDiff.cpp : 定义控制台应用程序的入口点。
//三帧差分法

#include "stdafx.h"
#include <cv.h>  
#include <cxcore.h>  
#include <highgui.h>  


// FFMpeg + OpenCV demo
#include <stdio.h>
#include <opencv2/core/core.hpp>
#include <opencv2/highgui/highgui.hpp>

#ifdef __cplusplus
extern "C" {
#endif

#include <libavformat/avformat.h>
#include <libavcodec/avcodec.h>
#include <libswscale/swscale.h>

#ifdef __cplusplus
}
#endif

#pragma comment(lib, "opencv_core330d.lib")
#pragma comment(lib, "opencv_highgui330d.lib")

#pragma comment(lib, "avcodec.lib")
#pragma comment(lib, "avformat.lib")
#pragma comment(lib, "avutil.lib")	
#pragma comment(lib ,"swscale.lib")

//CAM定义用摄像头获得视频else文件
//#define CAM   
int apos2 = 30;
void on_trackbar2(int pos)
{
	apos2 = pos;
}

static void CopyData(AVFrame *pFrame, int width, int height, int time);
int diffFrame(IplImage* pFrame, int width, int height);

int test_outline(int argc, const char * argv[])
{
	AVFormatContext *pFormatCtx = NULL;
	int             i, videoStream;
	AVCodecContext  *pCodecCtx;
	AVCodec         *pCodec;
	AVFrame         *pFrame;
	AVFrame         *pFrameRGB;
	AVPacket        packet;
	int             frameFinished;
	int             numBytes;
	uint8_t         *buffer;

	// Register all formats and codecs
	av_register_all();

	const char* videoFile = "vtest.avi";

	// Open video file
	if (avformat_open_input(&pFormatCtx, videoFile, NULL, NULL) != 0)
		// if(avformat_open_input(NULL, argv[1], NULL, NULL)!=0)
		return -1; // Couldn't open file

				   // Retrieve stream information
				   //if (av_find_stream_info(pFormatCtx)<0)
	if (avformat_find_stream_info(pFormatCtx, NULL) < 0)
		return -1; // Couldn't find stream information

				   // Dump information about file onto standard error
	av_dump_format(pFormatCtx, 0, argv[1], false);

	// Find the first video stream
	videoStream = -1;
	for (i = 0; i < pFormatCtx->nb_streams; i++)
	{
		if (pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO)
		{
			videoStream = i;
			break;
		}
	}

	if (videoStream == -1)
		return -1; // Didn't find a video stream

				   // Get a pointer to the codec context for the video stream
	pCodecCtx = pFormatCtx->streams[videoStream]->codec;

	// Find the decoder for the video stream
	pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
	if (pCodec == NULL)
		return -1; // Codec not found

				   // Open codec
	if (avcodec_open2(pCodecCtx, pCodec, 0) < 0)
		return -1; // Could not open codec

				   // Hack to correct wrong frame rates that seem to be generated by some codecs
	if (pCodecCtx->time_base.num > 1000 && pCodecCtx->time_base.den == 1)
		pCodecCtx->time_base.den = 1000;

	// Allocate video frame
	//pFrame = avcodec_alloc_frame();
	pFrame = av_frame_alloc();

	// Allocate an AVFrame structure
	//pFrameRGB = avcodec_alloc_frame();
	pFrameRGB = av_frame_alloc();
	if (pFrameRGB == NULL)
		return -1;

	// Determine required buffer size and allocate buffer
	numBytes = avpicture_get_size(AV_PIX_FMT_RGB24, pCodecCtx->width,
		pCodecCtx->height);

	//buffer=malloc(numBytes);
	buffer = (uint8_t *)av_malloc(numBytes*sizeof(uint8_t));

	// Assign appropriate parts of buffer to image planes in pFrameRGB
	avpicture_fill((AVPicture *)pFrameRGB, buffer, AV_PIX_FMT_RGB24,
		pCodecCtx->width, pCodecCtx->height);

	// Read frames and save first five frames to disk
	i = 0;
	long prepts = 0;
	while (av_read_frame(pFormatCtx, &packet) >= 0)
	{
		// Is this a packet from the video stream?
		if (packet.stream_index == videoStream)
		{
			// Decode video frame
			avcodec_decode_video2(pCodecCtx, pFrame, &frameFinished, &packet);

			// Did we get a video frame?
			if (frameFinished)
			{
				static struct SwsContext *img_convert_ctx;

#if 0
				// Older removed code
				// Convert the image from its native format to RGB swscale
				img_convert((AVPicture *)pFrameRGB, PIX_FMT_RGB24,
					(AVPicture*)pFrame, pCodecCtx->pix_fmt, pCodecCtx->width,
					pCodecCtx->height);

				// function template, for reference
				int sws_scale(struct SwsContext *context, uint8_t* src[], int srcStride[], int srcSliceY,
					int srcSliceH, uint8_t* dst[], int dstStride[]);
#endif
				// Convert the image into YUV format that SDL uses
				if (img_convert_ctx == NULL) {
					int w = pCodecCtx->width;
					int h = pCodecCtx->height;

					img_convert_ctx = sws_getContext(w, h,
						pCodecCtx->pix_fmt,
						w, h, AV_PIX_FMT_RGB24, SWS_BICUBIC,
						NULL, NULL, NULL);
					if (img_convert_ctx == NULL) {
						fprintf(stderr, "Cannot initialize the conversion context!\n");
						exit(1);
					}
				}
				int ret = sws_scale(img_convert_ctx, pFrame->data, pFrame->linesize, 0,
					pCodecCtx->height, pFrameRGB->data, pFrameRGB->linesize);
#if 0 
				// this use to be true, as of 1/2009, but apparently it is no longer true in 3/2009
				if (ret) {
					fprintf(stderr, "SWS_Scale failed [%d]!\n", ret);
					exit(-1);
				}
#endif

				CopyData(pFrameRGB, pCodecCtx->width, pCodecCtx->height, packet.pts - prepts);
				prepts = packet.pts;
			}
		}

		// Free the packet that was allocated by av_read_frame
		av_free_packet(&packet);
	}

	// Free the RGB image
	//free(buffer);
	av_free(buffer);
	av_free(pFrameRGB);

	// Free the YUV frame
	av_free(pFrame);

	// Close the codec
	avcodec_close(pCodecCtx);

	// Close the video file
	avformat_close_input(&pFormatCtx);

	system("Pause");

	return 0;
}

static void CopyData(AVFrame *pFrame, int width, int height, int time)
{
	if (time <= 0) time = 1;

	int		nChannels;
	int		stepWidth;
	uchar*	pData;
	cv::Mat frameImage(cv::Size(width, height), CV_8UC3, cv::Scalar(0));
	stepWidth = frameImage.step;
	nChannels = frameImage.channels();
	pData = frameImage.data;

	for (int i = 0; i < height; i++)
	{
		for (int j = 0; j < width; j++)
		{
			pData[i*stepWidth + j*nChannels + 0] = pFrame->data[0][i*pFrame->linesize[0] + j*nChannels + 2];
			pData[i*stepWidth + j*nChannels + 1] = pFrame->data[0][i*pFrame->linesize[0] + j*nChannels + 1];
			pData[i*stepWidth + j*nChannels + 2] = pFrame->data[0][i*pFrame->linesize[0] + j*nChannels + 0];
		}
	}

	IplImage* rgbFrame;
	rgbFrame = cvCreateImage(cvSize(width, height), IPL_DEPTH_8U, 3);
	*rgbFrame = frameImage;
	diffFrame(rgbFrame, width, height);

}

//帧数
static 	int nFrmNum = 0;
static bool bInit = false;

//声明IplImage指针  
//IplImage* pFrame = NULL; //原始视频帧  
static 	IplImage* pFrImg = NULL; //提取的前景图像，即运动目标  
static 	IplImage* pBkImg = NULL; //背景图像 
static 	IplImage* pMiImg = NULL; //中间帧图像

static 	CvMat* pFrameMat = NULL; //原始视频矩阵 
static 	CvMat* pFrMat = NULL;    //前景矩阵  第一帧
static 	CvMat* pBkMat = NULL;    //背景矩阵  第三帧
static 	CvMat* pMiMat = NULL;    //中间帧矩阵 第二帧
static 	CvMat* pRe1Mat = NULL;   //结果1
static 	CvMat* pRe2Mat = NULL;   //结果2

int diffFrame(IplImage* pFrame, int width, int height)
{
	if (!bInit)
	{
		//声明IplImage指针  
		//IplImage* pFrame = NULL; //原始视频帧  
		pFrImg = NULL; //提取的前景图像，即运动目标  
		pBkImg = NULL; //背景图像 
		pMiImg = NULL; //中间帧图像

		pFrameMat = NULL; //原始视频矩阵 
		pFrMat = NULL;    //前景矩阵  第一帧
		pBkMat = NULL;    //背景矩阵  第三帧
		pMiMat = NULL;    //中间帧矩阵 第二帧
		pRe1Mat = NULL;   //结果1
		pRe2Mat = NULL;   //结果2

						  //创建窗口  
		cvNamedWindow("video", 1);
		cvNamedWindow("background", 1);
		cvNamedWindow("foreground", 1);
		//使窗口有序排列  
		cvMoveWindow("video", 30, 0);
		cvMoveWindow("background", 360, 0);
		cvMoveWindow("foreground", 690, 0);

		// 滑动条          
		int nThreshold = 30;
		cvCreateTrackbar("阀值", "foreground", &nThreshold, 100, on_trackbar2);

		bInit = true;
	}


	{
		nFrmNum++;

		//如果是第一帧，需要申请内存，并初始化  
		if (nFrmNum == 1)
		{
			pBkImg = cvCreateImage(cvSize(width, height), IPL_DEPTH_8U, 1);
			pFrImg = cvCreateImage(cvSize( width,  height), IPL_DEPTH_8U, 1);

			pBkMat = cvCreateMat( height,  width, CV_32FC1);
			pFrMat = cvCreateMat( height,  width, CV_32FC1);
			pFrameMat = cvCreateMat( height,  width, CV_32FC1);
			pMiMat = cvCreateMat( height,  width, CV_32FC1);
			//转化成单通道图像再处理  
			cvCvtColor(pFrame, pBkImg, CV_BGR2GRAY); //第一帧作为背景了 
													 //cvCvtColor(pFrame, pFrImg, CV_BGR2GRAY); // 
													 //转换成矩阵
			cvConvert(pBkImg, pFrameMat);  //虽然没用，相当于给矩阵赋了初值
			cvConvert(pBkImg, pFrMat);	   //虽然没用，相当于给矩阵赋了初值
			cvConvert(pBkImg, pBkMat);
		}
		//如果是第er帧，需要申请内存，并初始化
		else if (nFrmNum == 2)
		{
			pMiImg = cvCreateImage(cvSize( width,  height), IPL_DEPTH_8U, 1);
			pMiMat = cvCreateMat( height,  width, CV_32FC1);
			pRe1Mat = cvCreateMat( height,  width, CV_32FC1);
			pRe2Mat = cvCreateMat( height,  width, CV_32FC1);
			cvCvtColor(pFrame, pMiImg, CV_BGR2GRAY);
			cvConvert(pMiImg, pMiMat);
		}
		else
		{
			cvCvtColor(pFrame, pFrImg, CV_BGR2GRAY);
			cvConvert(pFrImg, pFrameMat);
			//高斯滤波先，以平滑图像  
			//cvSmooth(pFrameMat, pFrameMat, CV_GAUSSIAN, 3, 0, 0);  

			//当前帧跟背景图相减 计算两个数组差的绝对值 
			cvAbsDiff(pMiMat, pBkMat, pRe1Mat);
			cvAbsDiff(pFrameMat, pMiMat, pRe2Mat);
			cvAnd(pRe1Mat, pRe2Mat, pFrMat, NULL);
			//二值化前景图  
			cvThreshold(pFrMat, pFrImg, apos2, 255.0, CV_THRESH_BINARY);

			//进行形态学滤波，去掉噪音    
			//cvErode(pFrImg, pFrImg, 0, 1);  
			//cvDilate(pFrImg, pFrImg, 0, 1);  
			/*cvDilate(pFrImg, pFrImg, 0, 1);
			cvErode(pFrImg, pFrImg, 0, 1);  */
			//更新背景  
			//cvRunningAvg(pFrameMat, pBkMat, 0.003, 0);  
			//将背景转化为图像格式，用以显示  
			cvConvert(pBkMat, pBkImg);
			cvCopy(pMiMat, pBkMat, NULL);
			cvCopy(pFrameMat, pMiMat, NULL);
			//pBkMat=pFrameMat;
			//显示图像  
			cvShowImage("video", pFrame);
			cvShowImage("background", pBkImg);
			cvShowImage("foreground", pFrImg);

			//如果有按键事件，则跳出循环  
			//此等待也为cvShowImage函数提供时间完成显示  
			//等待时间可以根据CPU速度调整  
			if (cvWaitKey(20) >= 0)
			{
				//break;
			}
		}
	}

	return 0;
	cvWaitKey();

	//销毁窗口  
	cvDestroyWindow("video");
	cvDestroyWindow("background");
	cvDestroyWindow("foreground");

	//释放图像和矩阵  
	cvReleaseImage(&pFrImg);
	cvReleaseImage(&pBkImg);
	cvReleaseImage(&pMiImg);

	cvReleaseMat(&pFrameMat);
	cvReleaseMat(&pFrMat);
	cvReleaseMat(&pBkMat);
	cvReleaseMat(&pMiMat);

	//cvReleaseCapture(&pCapture);

	return 0;
}

int test_algor2(int argc, char** argv)
{
	//声明IplImage指针  
	IplImage* pFrame = NULL; //原始视频帧  
	IplImage* pFrImg = NULL; //提取的前景图像，即运动目标  
	IplImage* pBkImg = NULL; //背景图像 
	IplImage* pMiImg = NULL; //中间帧图像

	CvMat* pFrameMat = NULL; //原始视频矩阵 
	CvMat* pFrMat = NULL;    //前景矩阵  第一帧
	CvMat* pBkMat = NULL;    //背景矩阵  第三帧
	CvMat* pMiMat = NULL;    //中间帧矩阵 第二帧
	CvMat* pRe1Mat = NULL;   //结果1
	CvMat* pRe2Mat = NULL;   //结果2
	CvCapture* pCapture = NULL;
	//帧数
	int nFrmNum = 0;

	//创建窗口  
	cvNamedWindow("video", 1);
	cvNamedWindow("background", 1);
	cvNamedWindow("foreground", 1);
	//使窗口有序排列  
	cvMoveWindow("video", 30, 0);
	cvMoveWindow("background", 360, 0);
	cvMoveWindow("foreground", 690, 0);
	// 滑动条          
	int nThreshold = 30;
	cvCreateTrackbar("阀值", "foreground", &nThreshold, 100, on_trackbar2);

#ifdef CAM
	if (!(pCapture = cvCaptureFromCAM(0)))
	{
		//pCapture = cvCaptureFromCAM(-1))  
		fprintf(stderr, "Can not open CAM .\n");
		return -2;
	}
#else
	char *filename = "driveway-320x240.avi";
	if (!(pCapture = cvCaptureFromAVI(filename)))
	{
		//pCapture = cvCaptureFromCAM(-1))  
		fprintf(stderr, "Can not open file %s.\n", filename);
		return -2;
	}
#endif
	//逐帧读取视频  
	while (pFrame = cvQueryFrame(pCapture))
	{
		nFrmNum++;

		//如果是第一帧，需要申请内存，并初始化  
		if (nFrmNum == 1)
		{
			pBkImg = cvCreateImage(cvSize(pFrame->width, pFrame->height), IPL_DEPTH_8U, 1);
			pFrImg = cvCreateImage(cvSize(pFrame->width, pFrame->height), IPL_DEPTH_8U, 1);

			pBkMat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			pFrMat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			pFrameMat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			pMiMat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			//转化成单通道图像再处理  
			cvCvtColor(pFrame, pBkImg, CV_BGR2GRAY); //第一帧作为背景了 
													 //cvCvtColor(pFrame, pFrImg, CV_BGR2GRAY); // 
													 //转换成矩阵
			cvConvert(pBkImg, pFrameMat);  //虽然没用，相当于给矩阵赋了初值
			cvConvert(pBkImg, pFrMat);	   //虽然没用，相当于给矩阵赋了初值
			cvConvert(pBkImg, pBkMat);
		}
		//如果是第er帧，需要申请内存，并初始化
		else if (nFrmNum == 2)
		{
			pMiImg = cvCreateImage(cvSize(pFrame->width, pFrame->height), IPL_DEPTH_8U, 1);
			pMiMat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			pRe1Mat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			pRe2Mat = cvCreateMat(pFrame->height, pFrame->width, CV_32FC1);
			cvCvtColor(pFrame, pMiImg, CV_BGR2GRAY);
			cvConvert(pMiImg, pMiMat);
		}
		else
		{
			cvCvtColor(pFrame, pFrImg, CV_BGR2GRAY);
			cvConvert(pFrImg, pFrameMat);
			//高斯滤波先，以平滑图像  
			//cvSmooth(pFrameMat, pFrameMat, CV_GAUSSIAN, 3, 0, 0);  

			//当前帧跟背景图相减 计算两个数组差的绝对值 
			cvAbsDiff(pMiMat, pBkMat, pRe1Mat);
			cvAbsDiff(pFrameMat, pMiMat, pRe2Mat);
			cvAnd(pRe1Mat, pRe2Mat, pFrMat, NULL);
			//二值化前景图  
			cvThreshold(pFrMat, pFrImg, apos2, 255.0, CV_THRESH_BINARY);

			//进行形态学滤波，去掉噪音    
			//cvErode(pFrImg, pFrImg, 0, 1);  
			//cvDilate(pFrImg, pFrImg, 0, 1);  
			/*cvDilate(pFrImg, pFrImg, 0, 1);
			cvErode(pFrImg, pFrImg, 0, 1);  */
			//更新背景  
			//cvRunningAvg(pFrameMat, pBkMat, 0.003, 0);  
			//将背景转化为图像格式，用以显示  
			cvConvert(pBkMat, pBkImg);
			cvCopy(pMiMat, pBkMat, NULL);
			cvCopy(pFrameMat, pMiMat, NULL);
			//pBkMat=pFrameMat;
			//显示图像  
			cvShowImage("video", pFrame);
			cvShowImage("background", pBkImg);
			cvShowImage("foreground", pFrImg);

			//如果有按键事件，则跳出循环  
			//此等待也为cvShowImage函数提供时间完成显示  
			//等待时间可以根据CPU速度调整  
			if (cvWaitKey(20) >= 0)
			{
				break;
			}
		}
	}
	cvWaitKey();

	//销毁窗口  
	cvDestroyWindow("video");
	cvDestroyWindow("background");
	cvDestroyWindow("foreground");

	//释放图像和矩阵  
	cvReleaseImage(&pFrImg);
	cvReleaseImage(&pBkImg);
	cvReleaseImage(&pMiImg);

	cvReleaseMat(&pFrameMat);
	cvReleaseMat(&pFrMat);
	cvReleaseMat(&pBkMat);
	cvReleaseMat(&pMiMat);

	cvReleaseCapture(&pCapture);

	return 0;
}

